{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yelpreview.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NextWaveGit/deeplearning/blob/master/yelpreview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aOGrAdSpiqh_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,CuDNNLSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "import keras.layers as layers\n",
        "from keras.engine import Layer\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "import time\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Other\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBwXTjGIjtqq",
        "colab_type": "code",
        "outputId": "aa1f3fda-6fae-454a-bda4-85539e877826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wSUFemsfkmvE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMCkLlXviqiC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = '/content/drive/My Drive/ml/yelp_review.csv'\n",
        "df = pd.read_csv(file, usecols = ['stars', 'text'], error_bad_lines=False,nrows=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "grT7EmIGiqiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df= df.dropna()\n",
        "#df = df[df.stars.apply(lambda x: x.isnumeric())]\n",
        "df = df[df.stars.apply(lambda x: x !=\"\")]\n",
        "df = df[df.text.apply(lambda x: x !=\"\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "x-nLr0lHiqiH",
        "colab_type": "code",
        "outputId": "2bd79719-cee6-4338-a9e0-1bfd932c7559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.731540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.386127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              stars\n",
              "count  50000.000000\n",
              "mean       3.731540\n",
              "std        1.386127\n",
              "min        1.000000\n",
              "25%        3.000000\n",
              "50%        4.000000\n",
              "75%        5.000000\n",
              "max        5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "USYuFsTAiqiM",
        "colab_type": "code",
        "outputId": "0033e305-aad5-4e97-a44d-5e8d5b4b068d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Super simple place but amazing nonetheless. It...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Small unassuming place that changes their menu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Love coming here. Yes the place always needs t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Had their chocolate almond croissant and it wa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text\n",
              "0      5  Super simple place but amazing nonetheless. It...\n",
              "1      5  Small unassuming place that changes their menu...\n",
              "2      5  Lester's is located in a beautiful neighborhoo...\n",
              "3      4  Love coming here. Yes the place always needs t...\n",
              "4      4  Had their chocolate almond croissant and it wa..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "YTRXOwE-iqiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = df['stars'].map(lambda x : 1 if int(x) > 3 else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5aOTHHvBb2g",
        "colab_type": "code",
        "outputId": "893674a6-d5e4-4e5e-ebae-2e9f693f29bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download(\"popular\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "XabGQekMiqiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "     \n",
        "    \n",
        "    ## Remove puncuation\n",
        "    text = text.translate(string.punctuation)\n",
        "    \n",
        "    ## Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "    \n",
        "    ## Remove stop words\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    \n",
        "    text = text.split()\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    stemmed_words = [stemmer.stem(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXIf54SEiqiT",
        "colab_type": "code",
        "outputId": "f5f6bd82-1fb0-4d6a-8d34-17ddbe266511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "df['text'] = df['text'].map(lambda x: clean_text(x))\n",
        "print(\"--- clean %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- clean 70.80327939987183 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DVFkpIKXiqiX",
        "colab_type": "code",
        "outputId": "292f6f49-48c0-48fe-a9df-88aca6c25bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>super simpl place amaz nonetheless around sinc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>small unassum place chang menu everi often coo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>lester locat beauti neighborhood sinc 1951 kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>love come here yes place alway need floor swep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>chocol almond croissant amaz ! light butteri c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>cycl pub las vega blast ! got groupon rent bik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>would guess would abl get fair decent vietname...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>alway drove past coffe hous wonder it final ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>bad ! ! love gluten - free vegan version chees...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>love place ! + + peggi great dog great job ! p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text\n",
              "0      5  super simpl place amaz nonetheless around sinc...\n",
              "1      5  small unassum place chang menu everi often coo...\n",
              "2      5  lester locat beauti neighborhood sinc 1951 kno...\n",
              "3      4  love come here yes place alway need floor swep...\n",
              "4      4  chocol almond croissant amaz ! light butteri c...\n",
              "5      5  cycl pub las vega blast ! got groupon rent bik...\n",
              "6      4  would guess would abl get fair decent vietname...\n",
              "7      4  alway drove past coffe hous wonder it final ma...\n",
              "8      3  bad ! ! love gluten - free vegan version chees...\n",
              "9      5  love place ! + + peggi great dog great job ! p..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "V_7IcO2eiqic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocabulary_size = 20000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['text'])\n",
        "data = pad_sequences(sequences, maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMv6MT-Ziqif",
        "colab_type": "code",
        "outputId": "d3165947-35cd-469c-f11c-6f7f60c9de2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ThHPH_q6iqii",
        "colab_type": "code",
        "outputId": "a581931c-f131-4158-df7b-824f21ffea26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "print(data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0   157   553     2    76  2340   104\n",
            "   120   575    88   125    55   162   590 10055  3557   150  1566    37\n",
            "    92    17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mgI0Indciqil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(vocabulary_size, 100, input_length=50))\n",
        "model_lstm.add(CuDNNLSTM(100))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3s2BZz7piqio",
        "colab_type": "code",
        "outputId": "5ce42d84-6e97-4e03-e36f-7fcd1795dbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "model_lstm.fit(data, np.array(labels), validation_split=0.4, batch_size=128, epochs=10)\n",
        "print(\"--- LSTM train %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 11s 355us/step - loss: 0.4239 - acc: 0.8036 - val_loss: 0.3370 - val_acc: 0.8594\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 5s 179us/step - loss: 0.2880 - acc: 0.8809 - val_loss: 0.3352 - val_acc: 0.8563\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 5s 176us/step - loss: 0.2272 - acc: 0.9105 - val_loss: 0.3654 - val_acc: 0.8478\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 5s 175us/step - loss: 0.1770 - acc: 0.9313 - val_loss: 0.4698 - val_acc: 0.8428\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 5s 174us/step - loss: 0.1417 - acc: 0.9470 - val_loss: 0.4704 - val_acc: 0.8344\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 5s 176us/step - loss: 0.1115 - acc: 0.9584 - val_loss: 0.5527 - val_acc: 0.8276\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 5s 172us/step - loss: 0.0942 - acc: 0.9666 - val_loss: 0.5893 - val_acc: 0.8245\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 5s 173us/step - loss: 0.0728 - acc: 0.9747 - val_loss: 0.7137 - val_acc: 0.8172\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 5s 175us/step - loss: 0.0528 - acc: 0.9819 - val_loss: 0.7869 - val_acc: 0.8226\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 5s 172us/step - loss: 0.0433 - acc: 0.9856 - val_loss: 0.8112 - val_acc: 0.8194\n",
            "--- LSTM train 58.40600037574768 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yuPGE5CYiqiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_conv_model():\n",
        "    model_conv = Sequential()\n",
        "    model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
        "    model_conv.add(Dropout(0.2))\n",
        "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
        "    model_conv.add(MaxPooling1D(pool_size=4))\n",
        "    #model_conv.add(LSTM(100))\n",
        "    model_conv.add(Flatten())\n",
        "    model_conv.add(Dense(1, activation='sigmoid'))\n",
        "    model_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model_conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGmry6Q4iqiy",
        "colab_type": "code",
        "outputId": "c9e2e021-a675-47a8-cd37-a63d3e145f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "model_conv = create_conv_model()\n",
        "model_conv.fit(data, np.array(labels), validation_split=0.4, batch_size=128, epochs = 10)\n",
        "print(\"--- CNN train %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 5s 168us/step - loss: 0.4825 - acc: 0.7601 - val_loss: 0.3539 - val_acc: 0.8484\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 3s 104us/step - loss: 0.3107 - acc: 0.8696 - val_loss: 0.3428 - val_acc: 0.8538\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.2382 - acc: 0.9063 - val_loss: 0.3656 - val_acc: 0.8465\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.1658 - acc: 0.9394 - val_loss: 0.4110 - val_acc: 0.8397\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.0969 - acc: 0.9700 - val_loss: 0.4838 - val_acc: 0.8337\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 3s 104us/step - loss: 0.0520 - acc: 0.9862 - val_loss: 0.5697 - val_acc: 0.8281\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 3s 104us/step - loss: 0.0276 - acc: 0.9938 - val_loss: 0.6571 - val_acc: 0.8290\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.0160 - acc: 0.9971 - val_loss: 0.7325 - val_acc: 0.8268\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.0101 - acc: 0.9984 - val_loss: 0.7963 - val_acc: 0.8266\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 3s 103us/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.8595 - val_acc: 0.8262\n",
            "--- CNN train 33.52278232574463 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SM2-2ttBiqi5",
        "colab_type": "code",
        "outputId": "a7cdc087-ab1f-40b4-88ac-af93a8df043d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/My Drive/ml/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WalxU-pWiqi9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ssPb_i_aiqi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
        "model_glove.add(Dropout(0.2))\n",
        "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "#model_glove.add(LSTM(100))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7alqhVuSiqjB",
        "colab_type": "code",
        "outputId": "371a82a8-ba63-4814-f71a-e3b9efce6fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "model_glove.fit(data, np.array(labels), validation_split=0.4, batch_size = 128, epochs = 10)\n",
        "print(\"--- glove train %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 4s 138us/step - loss: 0.5856 - acc: 0.6924 - val_loss: 0.5279 - val_acc: 0.7378\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.5149 - acc: 0.7435 - val_loss: 0.4934 - val_acc: 0.7580\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.4850 - acc: 0.7659 - val_loss: 0.4778 - val_acc: 0.7696\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.4591 - acc: 0.7828 - val_loss: 0.4771 - val_acc: 0.7681\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.4383 - acc: 0.7969 - val_loss: 0.5057 - val_acc: 0.7546\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.4164 - acc: 0.8077 - val_loss: 0.4642 - val_acc: 0.7788\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.3972 - acc: 0.8207 - val_loss: 0.4629 - val_acc: 0.7774\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 2s 76us/step - loss: 0.3796 - acc: 0.8306 - val_loss: 0.4710 - val_acc: 0.7732\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.3669 - acc: 0.8349 - val_loss: 0.4770 - val_acc: 0.7751\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 2s 75us/step - loss: 0.3527 - acc: 0.8420 - val_loss: 0.4687 - val_acc: 0.7788\n",
            "--- glove train 24.840129852294922 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IS1WfnT4R_ZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n",
        "\n",
        "class ElmoEmbeddingLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable=True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "\n",
        "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "                      as_dict=True,\n",
        "                      signature='default',\n",
        "                      )['default']\n",
        "        return result\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return K.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LL_T5DRXTnsD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to build model\n",
        "def build_model(): \n",
        "  input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
        "  embedding = ElmoEmbeddingLayer()(input_text)\n",
        "  dense = layers.Dense(256, activation='relu')(embedding)\n",
        "  pred = layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "  model = Model(inputs=[input_text], outputs=pred)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKCY6EC_LaLL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "\n",
        "# Create datasets (Only take up to 150 words for memory)\n",
        "texts = df['text'].tolist()\n",
        "texts = [' '.join(t.split()[0:50]) for t in texts]\n",
        "texts = np.array(texts, dtype=object)[:, np.newaxis]\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(texts, labeles, test_size=0.4, random_state=seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwDZCSG5UiUf",
        "colab_type": "code",
        "outputId": "0676805e-7333-42f3-81e9-268dd0a476fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "cell_type": "code",
      "source": [
        "# Build and fit\n",
        "model_elmo = build_model()\n",
        "model_elmo.fit(texts, \n",
        "          np.array(labels),\n",
        "          validation_split=0.4, batch_size = 128, epochs = 10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "elmo_embedding_layer_2 (Elmo (None, 1024)              4         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 262,661\n",
            "Trainable params: 262,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 488s 16ms/step - loss: 0.4950 - acc: 0.7521 - val_loss: 0.4415 - val_acc: 0.7946\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 485s 16ms/step - loss: 0.4506 - acc: 0.7805 - val_loss: 0.4252 - val_acc: 0.8018\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 484s 16ms/step - loss: 0.4364 - acc: 0.7882 - val_loss: 0.4158 - val_acc: 0.8061\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 485s 16ms/step - loss: 0.4228 - acc: 0.7957 - val_loss: 0.4052 - val_acc: 0.8123\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 484s 16ms/step - loss: 0.4134 - acc: 0.8037 - val_loss: 0.4206 - val_acc: 0.8000\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 484s 16ms/step - loss: 0.4067 - acc: 0.8070 - val_loss: 0.3952 - val_acc: 0.8173\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 484s 16ms/step - loss: 0.3992 - acc: 0.8126 - val_loss: 0.3970 - val_acc: 0.8162\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 484s 16ms/step - loss: 0.3934 - acc: 0.8145 - val_loss: 0.4010 - val_acc: 0.8093\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 485s 16ms/step - loss: 0.3865 - acc: 0.8184 - val_loss: 0.3955 - val_acc: 0.8164\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 485s 16ms/step - loss: 0.3776 - acc: 0.8251 - val_loss: 0.4234 - val_acc: 0.8041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4750c02b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "q4l3OzDfT6oh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build and fit\n",
        "model_elmo = build_model()\n",
        "model_elmo.fit(texts, \n",
        "          np.array(labels),\n",
        "          validation_split=0.4, batch_size = 32, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}